{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "from time import time\n",
    "import sys,argparse\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from operator import add\n",
    "from pyspark.mllib.random import RandomRDDs\n",
    "import pickle\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap((x,y)):\n",
    "    return (y,x)\n",
    "\n",
    "def predict(u,v):\n",
    "    return np.dot(u, v)\n",
    "\n",
    "def pred_diff(r,u,v):\n",
    "    return predict(u, v) - r    \n",
    "\n",
    "def gradient_u(delta,u,v):\n",
    "    return 2 * delta * v\n",
    "\n",
    "def gradient_v(delta,u,v):\n",
    "    return 2 * delta * u\n",
    "\n",
    "def readRatings(file,sparkContext):\n",
    "    return sparkContext.textFile(file).map(lambda x: tuple(x.split(','))).map(lambda (i,j,rij):(int(i),int(j),float(rij)))\n",
    "\n",
    "def generateUserProfiles(R,d,seed,sparkContext,N):\n",
    "    # exctract user ids\n",
    "    U = R.map(lambda (i,j,rij):i).distinct(numPartitions = N)\n",
    "    numUsers = U.count()\n",
    "    randRDD = RandomRDDs.normalVectorRDD(sparkContext, numUsers, d,numPartitions=N, seed=seed)\n",
    "    U = U.zipWithIndex().map(swap)\n",
    "    randRDD = randRDD.zipWithIndex().map(swap)\n",
    "    return U.join(randRDD,numPartitions = N).values()\n",
    "\n",
    "def generateItemProfiles(R,d,seed,sparkContext,N):\n",
    "    # extract item ids\n",
    "    V = R.map(lambda (i,j,rij):j).distinct(numPartitions = N)\n",
    "    numItems = V.count()\n",
    "    randRDD = RandomRDDs.normalVectorRDD(sparkContext, numItems, d,numPartitions=N, seed=seed)\n",
    "    V = V.zipWithIndex().map(swap)\n",
    "    randRDD = randRDD.zipWithIndex().map(swap)\n",
    "    return V.join(randRDD,numPartitions = N).values()\n",
    "\n",
    "def joinAndPredictAll(R,U,V,N):\n",
    "    return (R.map(lambda (i, j, rij): (i, (j, rij)))\n",
    "             .join(U, numPartitions = N)\n",
    "             .map(lambda (i, ((j, rij), ui)): (j, (i, ui, rij)))\n",
    "             .join(V, numPartitions = N)\n",
    "             .map(lambda (j, ((i, ui, rij), vj)): (i, j, pred_diff(rij, ui, vj), ui, vj)))\n",
    "\n",
    "\n",
    "def SE(joinedRDD):\n",
    "    return joinedRDD.map(lambda (i, j, dij, ui, vj): dij**2).sum()\n",
    "\n",
    "def normSqRDD(profileRDD,param):\n",
    "    return param * profileRDD.map(lambda (i, ui): np.linalg.norm(ui)**2).sum()\n",
    "\n",
    "\n",
    "def adaptU(joinedRDD,gamma,lam,N):\n",
    "    return (joinedRDD.map(lambda (i, _, dij, ui, vj): (i, (ui, gradient_u(dij, ui, vj))))\n",
    "                     .reduceByKey(lambda (ui, grad1), (_, grad2): (ui, grad1 + grad2), numPartitions = N)\n",
    "                     .map(lambda (i, (ui, grad)): (i, ui - gamma * (grad + 2 * lam * ui))))\n",
    "\n",
    "\n",
    "def adaptV(joinedRDD,gamma,mu,N):\n",
    "    return (joinedRDD.map(lambda (_, j, dij, ui, vj): (j, (vj, gradient_v(dij, ui, vj))))\n",
    "                     .reduceByKey(lambda (vj, grad1), (_, grad2): (vj, grad1 + grad2), numPartitions = N)\n",
    "                     .map(lambda (j, (vj, grad)): (j, vj - gamma * (grad + 2 * mu * vj))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args(data, \n",
    "            folds, \n",
    "            gain = 0.001, \n",
    "            power = 0.2, \n",
    "            epsilon = 1e-99, \n",
    "            lam = 1.0, \n",
    "            mu = 1.0, \n",
    "            d = 10, \n",
    "            outputfile = None,\n",
    "            maxiter = 20, \n",
    "            N = 40, \n",
    "            seed = 1234567, \n",
    "            output = None, \n",
    "            verbose=False):\n",
    "    '''\n",
    "    Parallele Matrix Factorization.\n",
    "\n",
    "    positional arguments:\n",
    "      data                  Directory containing folds. The folds should be named\n",
    "                            fold0, fold1, ..., foldK.\n",
    "      folds                 Number of folds\n",
    "\n",
    "    optional arguments:\n",
    "      -h, --help            show this help message and exit\n",
    "      --gain GAIN           Gain (default: 0.001)\n",
    "      --power POWER         Gain Exponent (default: 0.2)\n",
    "      --epsilon EPSILON     Desired objective accuracy (default: 1e-99)\n",
    "      --lam LAM             Regularization parameter for user features (default:\n",
    "                            1.0)\n",
    "      --mu MU               Regularization parameter for item features (default:\n",
    "                            1.0)\n",
    "      --d D                 Number of latent features (default: 10)\n",
    "      --outputfile OUTPUTFILE\n",
    "                            Output file (default: None)\n",
    "      --maxiter MAXITER     Maximum number of iterations (default: 20)\n",
    "      --N N                 Parallelization Level (default: 40)\n",
    "      --seed SEED           Seed used in random number generator (default:\n",
    "                            1234567)\n",
    "      --output OUTPUT       If not None, cross validation is skipped, and U,V are\n",
    "                            trained over entire dataset and store it in files\n",
    "                            output_U and output_V (default: None)\n",
    "      --verbose\n",
    "      --silent\n",
    "    '''\n",
    "    import sys\n",
    "\n",
    "    sys.argv = ['main',\n",
    "                str(data),\n",
    "                str(folds),\n",
    "                '--gain', str(gain),\n",
    "                '--power', str(power),\n",
    "                '--epsilon', str(epsilon),\n",
    "                '--lam', str(lam),\n",
    "                '--mu', str(mu),\n",
    "                '--d', str(d),\n",
    "                '--maxiter', str(maxiter),\n",
    "                '--N', str(N),\n",
    "                '--seed', str(seed)]\n",
    "    \n",
    "    if outputfile is not None:\n",
    "        sys.argv.append('--outputfile', str(outputfile))\n",
    "        \n",
    "    if output is not None:\n",
    "        sys.argv.append('--output', str(output))\n",
    "        \n",
    "    if verbose:\n",
    "        sys.argv.append('--verbose')\n",
    "    else:\n",
    "        sys.argv.append('--silent')\n",
    "        \n",
    "    parser = argparse.ArgumentParser(description = 'Parallele Matrix Factorization.',formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    parser.add_argument('data',help = 'Directory containing folds. The folds should be named fold0, fold1, ..., foldK.')\n",
    "    parser.add_argument('folds',type = int,help = 'Number of folds')\n",
    "    parser.add_argument('--gain',default=0.001,type=float,help =\"Gain\")\n",
    "    parser.add_argument('--power',default=0.2,type=float,help =\"Gain Exponent\")\n",
    "    parser.add_argument('--epsilon',default=1.e-99,type=float,help =\"Desired objective accuracy\")\n",
    "    parser.add_argument('--lam',default=1.0,type=float,help =\"Regularization parameter for user features\")\n",
    "    parser.add_argument('--mu',default=1.0,type=float,help =\"Regularization parameter for item features\")\n",
    "    parser.add_argument('--d',default=10,type=int,help =\"Number of latent features\")\n",
    "    parser.add_argument('--outputfile',help = 'Output file')\n",
    "    parser.add_argument('--maxiter',default=20,type=int, help='Maximum number of iterations')\n",
    "    parser.add_argument('--N',default=40,type=int, help='Parallelization Level')\n",
    "    parser.add_argument('--seed',default=1234567,type=int, help='Seed used in random number generator')\n",
    "    parser.add_argument('--output',default=None, help='If not None, cross validation is skipped, and U,V are trained over entire dataset and store it in files output_U and output_V')\n",
    "\n",
    "    verbosity_group = parser.add_mutually_exclusive_group(required=False)\n",
    "    verbosity_group.add_argument('--verbose', dest='verbose', action='store_true')\n",
    "    verbosity_group.add_argument('--silent', dest='verbose', action='store_false')\n",
    "    parser.set_defaults(verbose=False)\n",
    "\n",
    "    return parser.parse_args()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, sc):\n",
    "    folds = {}\n",
    "\n",
    "    if args.output is None:\n",
    "        for k in range(args.folds):\n",
    "            folds[k] = readRatings(args.data+\"/fold\"+str(k),sc)\n",
    "    else:\n",
    "        folds[0] = readRatings(args.data,sc)\n",
    "\n",
    "    cross_val_rmses = []\n",
    "    for k in folds:\n",
    "        train_folds = [folds[j] for j in folds if j is not k ]  # excludes one fold for training\n",
    "\n",
    "        if len(train_folds)>0:\n",
    "            train = train_folds[0] \n",
    "            for fold in  train_folds[1:]:\n",
    "                train=train.union(fold)  # combines all training folds\n",
    "            train.repartition(args.N).cache()\n",
    "            test = folds[k].repartition(args.N).cache()  # uses excluded fold for testing\n",
    "            Mtrain=train.count()\n",
    "            Mtest=test.count()\n",
    "\n",
    "            print(\"Initiating fold %d with %d train samples and %d test samples\" % (k,Mtrain,Mtest) )\n",
    "        else:\n",
    "            train = folds[k].repartition(args.N).cache()\n",
    "            test = train\n",
    "            Mtrain=train.count()\n",
    "            Mtest=test.count()\n",
    "            print(\"Running single training over training set with %d train samples. Test RMSE computes RMSE on training set\" % Mtrain )\n",
    "\n",
    "        i = 0\n",
    "        change = 1.e99\n",
    "        obj = 1.e99\n",
    "\n",
    "        #Generate user profiles\n",
    "        U = generateUserProfiles(train,args.d,args.seed,sc,args.N).cache()\n",
    "        V = generateItemProfiles(train,args.d,args.seed,sc,args.N).cache()\n",
    "\n",
    "        print \"Training set contains %d users and %d items\" %(U.count(),V.count())\n",
    "\n",
    "        start = time()\n",
    "        gamma = args.gain\n",
    "\n",
    "        while i<args.maxiter and change > args.epsilon:\n",
    "            i += 1\n",
    "\n",
    "            joinedRDD = joinAndPredictAll(train,U,V,args.N).cache()\n",
    "\n",
    "            oldObjective = obj\n",
    "            obj = SE(joinedRDD) + normSqRDD(U,args.lam) + normSqRDD(V,args.lam)         \n",
    "            change = np.abs(obj-oldObjective) \n",
    "\n",
    "            testRMSE = np.sqrt(1.*SE(joinAndPredictAll(test,U,V,args.N))/Mtest)\n",
    "\n",
    "            gamma = args.gain / i**args.power\n",
    "            U.unpersist()\n",
    "            V.unpersist()\n",
    "            U = adaptU(joinedRDD,gamma,args.lam,args.N).cache()\n",
    "            V = adaptV(joinedRDD,gamma,args.mu,args.N).cache()\n",
    "\n",
    "            now = time()-start\n",
    "            print \"Iteration: %d\\tTime: %f\\tObjective: %f\\tTestRMSE: %f\" % (i,now,obj,testRMSE)\n",
    "\n",
    "            joinedRDD.unpersist()\n",
    "\n",
    "        cross_val_rmses.append(testRMSE)\n",
    "\n",
    "        train.unpersist()\n",
    "        test.unpersist()\n",
    "\n",
    "    if args.output is None:\n",
    "       print \"%d-fold cross validation error is: %f \" % (args.folds, np.mean(cross_val_rmses))\n",
    "    else:\n",
    "       print \"Saving U and V RDDs\"\n",
    "       U.saveAsTextFile(args.output+'_U')\n",
    "       V.saveAsTextFile(args.output+'_V')\n",
    "    return U, V, np.mean(cross_val_rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SparkContext.setSystemProperty('spark.executor.memory', '100g')\n",
    "SparkContext.setSystemProperty('spark.driver.memory', '100g')\n",
    "try:\n",
    "    sc = SparkContext('local[40]', appName='Parallel MF')\n",
    "except:\n",
    "    sc = SparkContext.getOrCreate()\n",
    "    SparkContext.stop(sc)\n",
    "    sc = SparkContext('local[40]', appName='Parallel MF')\n",
    "spark = SparkSession(sc)\n",
    "sc.setLogLevel(\"ERROR\")   \n",
    "sc.setCheckpointDir('checkpoint/')\n",
    "sess = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SparkContext.stop(sc)\n",
    "# SparkContext.setSystemProperty('spark.executor.memory', '100g')\n",
    "# SparkContext.setSystemProperty('spark.driver.memory', '100g')\n",
    "# sc = SparkContext(\"spark://10.99.248.66:7077\", appName='Parallel MF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "lam: 0, mu: 0, d: 4\n",
      "Initiating fold 0 with 1214782 train samples and 303696 test samples\n",
      "Training set contains 30628 users and 45598 items\n",
      "Iteration: 1\tTime: 13.526918\tObjective: 23321780.210041\tTestRMSE: 4.336444\n",
      "Iteration: 2\tTime: 32.030892\tObjective: 20190044.146563\tTestRMSE: 4.046689\n",
      "Iteration: 3\tTime: 50.337365\tObjective: 19613391.544992\tTestRMSE: 3.994389\n",
      "Iteration: 4\tTime: 68.790392\tObjective: 19318196.266172\tTestRMSE: 3.968597\n",
      "Iteration: 5\tTime: 87.190355\tObjective: 19124263.648308\tTestRMSE: 3.951975\n",
      "Initiating fold 1 with 1214782 train samples and 303696 test samples\n",
      "Training set contains 30652 users and 45481 items\n",
      "Iteration: 1\tTime: 12.505722\tObjective: 23232067.437208\tTestRMSE: 4.326552\n",
      "Iteration: 2\tTime: 31.461591\tObjective: 20181544.100034\tTestRMSE: 4.044971\n",
      "Iteration: 3\tTime: 50.415086\tObjective: 19584838.704695\tTestRMSE: 3.989907\n",
      "Iteration: 4\tTime: 70.716989\tObjective: 19258572.774153\tTestRMSE: 3.961009\n",
      "Iteration: 5\tTime: 89.423533\tObjective: 19005543.340570\tTestRMSE: 3.938106\n",
      "Initiating fold 2 with 1214782 train samples and 303696 test samples\n",
      "Training set contains 30746 users and 45634 items\n",
      "Iteration: 1\tTime: 14.823787\tObjective: 23368075.412224\tTestRMSE: 4.334447\n",
      "Iteration: 2\tTime: 34.770682\tObjective: 20213159.697510\tTestRMSE: 4.043249\n",
      "Iteration: 3\tTime: 54.402154\tObjective: 19597483.048340\tTestRMSE: 3.988186\n",
      "Iteration: 4\tTime: 74.558907\tObjective: 19257783.298980\tTestRMSE: 3.957926\n",
      "Iteration: 5\tTime: 95.310599\tObjective: 18990423.561157\tTestRMSE: 3.933894\n",
      "Initiating fold 3 with 1214783 train samples and 303695 test samples\n",
      "Training set contains 30666 users and 45636 items\n",
      "Iteration: 1\tTime: 16.082340\tObjective: 23385242.507216\tTestRMSE: 4.349488\n",
      "Iteration: 2\tTime: 35.822739\tObjective: 20194809.094010\tTestRMSE: 4.053168\n",
      "Iteration: 3\tTime: 57.060749\tObjective: 19599508.986312\tTestRMSE: 3.999804\n",
      "Iteration: 4\tTime: 75.583367\tObjective: 19273718.890540\tTestRMSE: 3.970355\n",
      "Iteration: 5\tTime: 94.820060\tObjective: 19031053.395028\tTestRMSE: 3.948959\n",
      "Initiating fold 4 with 1214783 train samples and 303695 test samples\n",
      "Training set contains 30680 users and 45469 items\n",
      "Iteration: 1\tTime: 14.566021\tObjective: 23193474.574460\tTestRMSE: 4.316829\n",
      "Iteration: 2\tTime: 33.779825\tObjective: 20192219.436837\tTestRMSE: 4.045535\n",
      "Iteration: 3\tTime: 53.305929\tObjective: 19605305.092109\tTestRMSE: 3.993228\n",
      "Iteration: 4\tTime: 75.270692\tObjective: 19300388.271027\tTestRMSE: 3.966441\n",
      "Iteration: 5\tTime: 93.258411\tObjective: 19096970.564367\tTestRMSE: 3.949330\n",
      "5-fold cross validation error is: 3.944453 \n"
     ]
    }
   ],
   "source": [
    "epsilon = 1e-99 \n",
    "outputfile = None\n",
    "N = 40\n",
    "seed = 1234567 \n",
    "output = None \n",
    "verbose = False\n",
    "\n",
    "fold_nums = 5\n",
    "gain = 0.00025\n",
    "data_name = '../data/beer'\n",
    "power = 0.15\n",
    "maxiter = 5\n",
    "\n",
    "results = []\n",
    "for lam in range(0, 1):\n",
    "    for mu in range(0, 1):\n",
    "        for d in range(4, 5):\n",
    "            print('---------------------------------------')\n",
    "            print('lam: {}, mu: {}, d: {}'.format(lam, mu, d))\n",
    "            args = get_args(data_name, fold_nums, gain, power, epsilon, \n",
    "                             lam, mu, d, outputfile, maxiter, N, seed, \n",
    "                             output, verbose)\n",
    "            U, V, rms = train(args, sc)\n",
    "            results.append((lam, mu, d, rms))\n",
    "            with open('../results/mf/beer.pickle', 'wb+') as f:\n",
    "                pickle.dump(results, f)\n",
    "            with open('../results/mf/beer.txt', 'ab+') as f:\n",
    "                f.write('{} {} {} {}\\n'.format(lam, mu, d, rms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_str = U.map(lambda (x, y): ','.join(str(t) for t in [x] + list(y)))\n",
    "v_str = V.map(lambda (x, y): ','.join(str(t) for t in [x] + list(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0,-0.7297006140244157,1.4962763020067322,0.3896103832776914,-1.8935152510699058',\n",
       " '20480,1.040386587960158,0.01828241501710274,0.27204776714854917,-1.146878199684007']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_str.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_str.saveAsTextFile('u.csv')\n",
    "v_str.saveAsTextFile('v.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
